# scripts/data_quality_check.py
import pandas as pd
import os
import json
import datetime

# æ ¸å¿ƒæ•°æ®è·¯å¾„
ENGINE_DIR = "final_output/engine"
REPORT_DIR = "final_output/report"
os.makedirs(REPORT_DIR, exist_ok=True)

def check_stock_data():
    file_path = f"{ENGINE_DIR}/stock_full.parquet"
    if not os.path.exists(file_path):
        return {"error": "stock_full.parquet not found"}
    
    print(f"æ­£åœ¨æ£€æŸ¥ä¸ªè‚¡å®½è¡¨: {file_path} ...")
    
    # è¯»å–æ•°æ®
    df = pd.read_parquet(file_path)
    total_rows = len(df)
    
    if total_rows == 0:
        return {"error": "stock_full.parquet is empty"}

    # 1. åŸºç¡€ç»´åº¦
    unique_stocks = df['code'].nunique()
    min_date = str(df['date'].min())
    max_date = str(df['date'].max())
    
    # 2. ç¼ºå¤±å€¼æ£€æŸ¥ (Miss Rate)
    # èµ„é‡‘æµç¼ºå¤±ç‡ (main_net_flow ä¸ºç©ºæˆ–ä¸º0çš„æ¯”ä¾‹)
    # æ³¨æ„ï¼šmergeæ—¶å¦‚æœfillna(0)äº†ï¼Œè¦æŸ¥0ï¼›å¦‚æœæ˜¯NaNæŸ¥NaNã€‚
    # å‡è®¾ merge_data.py é‡Œæ²¡æœ‰ fillna(0)ï¼Œåˆ™æ˜¯ NaNã€‚
    # ä½†æœ‰äº›è„šæœ¬ä¹ æƒ¯ fillnaã€‚è¿™é‡Œæ£€æŸ¥ NaNã€‚
    missing_flow = df['main_net_flow'].isnull().sum()
    missing_pe = df['peTTM'].isnull().sum()
    missing_factor = df['adjustFactor'].isnull().sum()
    
    # 3. å¼‚å¸¸å€¼æ£€æŸ¥
    # æˆäº¤é‡ < 0
    neg_vol = (df['volume'] < 0).sum()
    # æ”¶ç›˜ä»· <= 0
    neg_close = (df['close'] <= 0).sum()
    
    # 4. ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
    summary = {
        "status": "Success",
        "total_rows": int(total_rows),
        "stock_count": int(unique_stocks),
        "date_range": f"{min_date} ~ {max_date}",
        "quality_metrics": {
            "missing_fund_flow_pct": round(missing_flow / total_rows * 100, 2),
            "missing_pe_pct": round(missing_pe / total_rows * 100, 2),
            "missing_factor_pct": round(missing_factor / total_rows * 100, 2),
            "negative_volume_count": int(neg_vol),
            "invalid_price_count": int(neg_close)
        }
    }
    
    # 5. ç®€å•çš„å¥åº·è¯„åˆ† (0-100)
    score = 100
    if summary['quality_metrics']['missing_fund_flow_pct'] > 50: score -= 20
    if summary['quality_metrics']['invalid_price_count'] > 0: score -= 50
    summary['health_score'] = score
    
    print(f"âœ… ä¸ªè‚¡æ•°æ®æ£€æŸ¥å®Œæˆã€‚å¥åº·åˆ†: {score}")
    return summary

def check_sector_data():
    file_path = f"{ENGINE_DIR}/sector_full.parquet"
    if not os.path.exists(file_path):
        return {"warning": "sector_full.parquet not found"}
    
    print(f"æ­£åœ¨æ£€æŸ¥æ¿å—å®½è¡¨: {file_path} ...")
    df = pd.read_parquet(file_path)
    
    return {
        "total_rows": int(len(df)),
        "sector_count": int(df['code'].nunique()),
        "date_range": f"{str(df['date'].min())} ~ {str(df['date'].max())}"
    }

def main():
    report = {
        "generate_time": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "stock_data": check_stock_data(),
        "sector_data": check_sector_data()
    }
    
    # ä¿å­˜ JSON æŠ¥å‘Š
    json_path = f"{REPORT_DIR}/quality_report.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
        
    # ç”Ÿæˆ Markdown æ‘˜è¦ (ç”¨äº GitHub Actions Job Summary)
    md_path = f"{REPORT_DIR}/summary.md"
    with open(md_path, "w", encoding="utf-8") as f:
        s = report['stock_data']
        q = s.get('quality_metrics', {})
        f.write(f"## ğŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š (Data Quality Report)\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {report['generate_time']}\n\n")
        
        f.write(f"### ğŸš€ ä¸ªè‚¡å…¨é‡è¡¨ (Stock Full)\n")
        f.write(f"- **å¥åº·è¯„åˆ†**: {s.get('health_score', 'N/A')} / 100\n")
        f.write(f"- **æ€»è®°å½•æ•°**: {s.get('total_rows', 0):,}\n")
        f.write(f"- **è‚¡ç¥¨æ•°é‡**: {s.get('stock_count', 0)}\n")
        f.write(f"- **æ—¥æœŸèŒƒå›´**: {s.get('date_range', '-')}\n")
        f.write(f"- **èµ„é‡‘æµç¼ºå¤±ç‡**: {q.get('missing_fund_flow_pct', 0)}%\n")
        f.write(f"- **å¤æƒå› å­ç¼ºå¤±ç‡**: {q.get('missing_factor_pct', 0)}%\n\n")
        
        sec = report['sector_data']
        f.write(f"### ğŸŒ æ¿å—å…¨é‡è¡¨ (Sector Full)\n")
        f.write(f"- **æ€»è®°å½•æ•°**: {sec.get('total_rows', 0):,}\n")
        f.write(f"- **æ¿å—æ•°é‡**: {sec.get('sector_count', 0)}\n")

    print(f"âœ… è´¨æ£€æŠ¥å‘Šå·²ç”Ÿæˆ: {json_path}")

if __name__ == "__main__":
    main()
