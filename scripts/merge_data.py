# scripts/merge_data.py
import pandas as pd
import glob
import os
from tqdm import tqdm
import pandas_ta as ta  # å¼•å…¥æŠ€æœ¯åˆ†æåº“
import numpy as np

# è¾“å…¥ç›®å½•
KLINE_DIR = "downloaded_kline" 
FLOW_DIR = "downloaded_fundflow"

# è¾“å‡ºç›®å½•
OUTPUT_DIR = "final_output/engine"
os.makedirs(OUTPUT_DIR, exist_ok=True)

def calculate_indicators(df):
    """
    è®¡ç®—æŠ€æœ¯æŒ‡æ ‡çš„æ ¸å¿ƒå‡½æ•°
    æ³¨æ„ï¼šä¼ å…¥çš„ df å¿…é¡»æ˜¯æŒ‰ date å‡åºæ’åˆ—çš„å•åªè‚¡ç¥¨æ•°æ®
    """
    # 1. å‡çº¿ (MA) - ä½¿ç”¨ Pandas Rolling (é€Ÿåº¦æœ€å¿«)
    for w in [5, 10, 20, 60, 120, 250]:
        df[f'ma{w}'] = df['close'].rolling(window=w).mean()
    
    # 2. å‡é‡ (Vol MA)
    for w in [5, 10, 20, 30]:
        df[f'vol_ma{w}'] = df['volume'].rolling(window=w).mean()

    # 3. MACD (12, 26, 9)
    # pandas_ta è¿”å›åˆ—å: MACD_12_26_9, MACDh_..., MACDs_...
    try:
        macd = df.ta.macd(close='close', fast=12, slow=26, signal=9)
        if macd is not None:
            df['dif'] = macd.iloc[:, 0]  # å¿«çº¿
            df['macd'] = macd.iloc[:, 1] # æŸ±çŠ¶å›¾ (æ³¨æ„ï¼šæœ‰äº›è½¯ä»¶dif/dea/macdé¡ºåºä¸åŒï¼Œéœ€æ ¸å¯¹)
            df['dea'] = macd.iloc[:, 2]  # æ…¢çº¿
    except: pass

    # 4. KDJ (9, 3, 3)
    try:
        kdj = df.ta.kdj(high='high', low='low', close='close', length=9, signal=3)
        if kdj is not None:
            df['k'] = kdj.iloc[:, 0]
            df['d'] = kdj.iloc[:, 1]
            df['j'] = kdj.iloc[:, 2]
    except: pass

    # 5. RSI (6, 12, 24)
    try:
        df['rsi6'] = df.ta.rsi(close='close', length=6)
        df['rsi12'] = df.ta.rsi(close='close', length=12)
        df['rsi24'] = df.ta.rsi(close='close', length=24)
    except: pass

    # 6. BOLL (20, 2)
    try:
        boll = df.ta.bbands(close='close', length=20, std=2)
        if boll is not None:
            df['boll_lb'] = boll.iloc[:, 0] # Lower
            # df['boll_mb'] = boll.iloc[:, 1] # Mid (å…¶å®å°±æ˜¯MA20)
            df['boll_up'] = boll.iloc[:, 2] # Upper
    except: pass

    # 7. CCI (14) & ATR (14)
    try:
        df['cci'] = df.ta.cci(high='high', low='low', close='close', length=14)
        df['atr'] = df.ta.atr(high='high', low='low', close='close', length=14)
    except: pass

    return df

def main():
    print("ğŸš€ å¼€å§‹å®½è¡¨åˆå¹¶ä¸æŒ‡æ ‡è®¡ç®—...")
    
    k_files = glob.glob(f"{KLINE_DIR}/**/*.parquet", recursive=True)
    f_files = glob.glob(f"{FLOW_DIR}/**/*.parquet", recursive=True)
    
    print(f"æ‰«æåˆ° Kçº¿: {len(k_files)}, èµ„é‡‘æµ: {len(f_files)}")
    
    f_map = {os.path.basename(f): f for f in f_files}
    
    all_dfs = []
    
    # 1. è¯»å–å¹¶åˆå¹¶åŸºç¡€æ•°æ®
    print("æ­£åœ¨åˆå¹¶åŸºç¡€æ•°æ®...")
    for k_path in tqdm(k_files, desc="Merging"):
        try:
            filename = os.path.basename(k_path)
            df_k = pd.read_parquet(k_path)
            if df_k.empty: continue
            
            df_k['date'] = pd.to_datetime(df_k['date'])
            
            if filename in f_map:
                df_f = pd.read_parquet(f_map[filename])
                if not df_f.empty:
                    df_f['date'] = pd.to_datetime(df_f['date'])
                    df_k = pd.merge(df_k, df_f, on=['date', 'code'], how='left')
            
            all_dfs.append(df_k)
        except Exception as e:
            print(f"Skipping {k_path}: {e}")

    if not all_dfs:
        print("âŒ æ— æœ‰æ•ˆæ•°æ®åˆå¹¶")
        return

    # 2. æ‹¼æ¥å…¨é‡å¤§è¡¨
    print("æ‹¼æ¥å…¨é‡ DataFrame...")
    full_df = pd.concat(all_dfs, ignore_index=True)
    
    # 3. æ’åº (è®¡ç®—æŒ‡æ ‡å‰å¿…é¡»æŒ‰ code, date æ’åº)
    print("æ’åº (Code + Date)...")
    full_df.sort_values(['code', 'date'], inplace=True)
    
    # 4. è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ (æœ€ä¸ºè€—æ—¶çš„æ­¥éª¤)
    print("ğŸ§® æ­£åœ¨è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ (MA, MACD, KDJ, RSI, BOLL, CCI, ATR)...")
    
    # æ–¹æ¡ˆï¼šä½¿ç”¨ groupby().apply()
    # æ³¨æ„ï¼šapply ä¼šæ¯”å‘é‡åŒ–æ…¢ï¼Œä½†è¿™æ˜¯è®¡ç®—å¤æ‚æŒ‡æ ‡æœ€ç¨³å¦¥çš„æ–¹æ³•
    # ä¸ºäº†æé€Ÿï¼Œæˆ‘ä»¬å…ˆå®šä¹‰å¥½ Schema
    full_df = full_df.groupby('code', group_keys=False).apply(calculate_indicators)
    
    # 5. æ•°æ®ç±»å‹ä¼˜åŒ– (ç˜¦èº«)
    print("ğŸ’¾ æ•°æ®ç±»å‹ä¼˜åŒ– (Float64 -> Float32)...")
    # æ‰¾å‡ºæ‰€æœ‰æµ®ç‚¹åˆ—
    float_cols = full_df.select_dtypes(include=['float64']).columns
    # ç»Ÿä¸€è½¬ä¸º float32 å¹¶ä¿ç•™ 3 ä½å°æ•°
    for col in float_cols:
        full_df[col] = full_df[col].round(3).astype('float32')

    # 6. è¿˜åŸæ—¥æœŸæ ¼å¼
    full_df['date'] = full_df['date'].dt.strftime('%Y-%m-%d')

    # 7. ä¿å­˜
    outfile = f"{OUTPUT_DIR}/stock_full.parquet"
    print(f"å†™å…¥ Parquet (ZSTD)... {outfile}")
    
    full_df.to_parquet(outfile, index=False, compression='zstd', row_group_size=100000)
    print(f"âœ… å®½è¡¨åˆå¹¶ä¸è®¡ç®—å®Œæˆï¼åŒ…å« {len(full_df.columns)} ä¸ªå­—æ®µã€‚")

if __name__ == "__main__":
    main()
