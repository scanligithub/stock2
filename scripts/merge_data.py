import pandas as pd
import glob
import os
from tqdm import tqdm

# è¾“å…¥ç›®å½• (GitHub Actions ä¼šæŠŠ Artifact ä¸‹è½½åˆ°è¿™é‡Œ)
KLINE_DIR = "downloaded_kline" 
FLOW_DIR = "downloaded_fundflow"

# è¾“å‡ºç›®å½•
OUTPUT_DIR = "final_output/engine"
os.makedirs(OUTPUT_DIR, exist_ok=True)

def main():
    print("ğŸš€ å¼€å§‹å®½è¡¨åˆå¹¶...")
    
    # 1. æ‰«ææ–‡ä»¶
    # æ³¨æ„ï¼šartifact ä¸‹è½½åå¯èƒ½æœ‰å¤šå±‚ç›®å½•ï¼Œè¿™é‡Œä½¿ç”¨é€’å½’æœç´¢
    k_files = glob.glob(f"{KLINE_DIR}/**/*.parquet", recursive=True)
    f_files = glob.glob(f"{FLOW_DIR}/**/*.parquet", recursive=True)
    
    print(f"Kçº¿æ–‡ä»¶: {len(k_files)}, èµ„é‡‘æµæ–‡ä»¶: {len(f_files)}")
    
    # å»ºç«‹ç´¢å¼•ï¼šæ–‡ä»¶å(code) -> æ–‡ä»¶è·¯å¾„
    f_map = {os.path.basename(f): f for f in f_files}
    
    all_dfs = []
    
    for k_path in tqdm(k_files, desc="Merging"):
        try:
            filename = os.path.basename(k_path)
            
            # è¯»å– Kçº¿ (å« PE/PB)
            df_k = pd.read_parquet(k_path)
            if df_k.empty: continue
            
            df_k['date'] = pd.to_datetime(df_k['date'])
            
            # å…³è”èµ„é‡‘æµ
            if filename in f_map:
                df_f = pd.read_parquet(f_map[filename])
                if not df_f.empty:
                    df_f['date'] = pd.to_datetime(df_f['date'])
                    # Left Join
                    df_k = pd.merge(df_k, df_f, on=['date', 'code'], how='left')
            
            # (å¯é€‰) åœ¨è¿™é‡Œå¤„ç† è´¢åŠ¡æ•°æ®å‘ä¸‹å¡«å…… (Forward Fill)
            # å¦‚æœä½ æœ‰å•ç‹¬çš„è´¢åŠ¡ Parquetï¼Œå¯ä»¥åœ¨è¿™é‡Œå† merge ä¸€æ¬¡
            
            all_dfs.append(df_k)
            
        except Exception as e:
            print(f"Error {filename}: {e}")

    if all_dfs:
        print("æ‹¼æ¥å…¨é‡è¡¨...")
        full_df = pd.concat(all_dfs, ignore_index=True)
        
        print("æ’åº (Code + Date)...")
        # è¿™ä¸€æ­¥å¯¹ DuckDB æ€§èƒ½è‡³å…³é‡è¦
        full_df.sort_values(['code', 'date'], inplace=True)
        
        outfile = f"{OUTPUT_DIR}/stock_full.parquet"
        print(f"å†™å…¥ Parquet (ZSTD)... {outfile}")
        
        # å…³é”®å‚æ•°ï¼šrow_group_size=100000 é…åˆ DuckDB è°“è¯ä¸‹æ¨
        full_df.to_parquet(outfile, index=False, compression='zstd', row_group_size=100000)
        print("âœ… å®½è¡¨åˆå¹¶æˆåŠŸ")
    else:
        print("âŒ æœªåˆå¹¶åˆ°ä»»ä½•æ•°æ®")

if __name__ == "__main__":
    main()
