# scripts/merge_data.py
import pandas as pd
import numpy as np
import pandas_ta as ta
import os
import glob
import datetime
import gc  # å¼•å…¥åƒåœ¾å›æ”¶æ¨¡å—
from tqdm import tqdm

# === è·¯å¾„é…ç½® ===
CACHE_DIR = "cache_data"          
KLINE_DIR = "downloaded_kline"    
FLOW_DIR = "downloaded_fundflow"  

# è¾“å‡ºç›®å½•
OUTPUT_ENGINE = "final_output/engine"
OUTPUT_DAILY = f"{OUTPUT_ENGINE}/stock_daily"

os.makedirs(OUTPUT_DAILY, exist_ok=True)

def optimize_float(df):
    """
    ã€å†…å­˜ä¼˜åŒ–æ ¸å¿ƒã€‘
    å°†æ‰€æœ‰ float64 é™çº§ä¸º float32ï¼ŒèŠ‚çœ 50% å†…å­˜
    """
    float_cols = df.select_dtypes(include=['float64']).columns
    if len(float_cols) > 0:
        df[float_cols] = df[float_cols].astype('float32')
    return df

def calculate_indicators(df):
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
    # 1. ä»·æ ¼å‡çº¿ (MA)
    for w in [5, 10, 20, 60, 120, 250]:
        df[f'ma{w}'] = df['close'].rolling(window=w).mean().astype('float32')
    
    # 2. æˆäº¤é‡å‡çº¿ (Vol MA)
    for w in [5, 10, 20, 30]:
        df[f'vol_ma{w}'] = df['volume'].rolling(window=w).mean().astype('float32')

    # 3. MACD
    try:
        macd = df.ta.macd(close='close', fast=12, slow=26, signal=9)
        if macd is not None:
            df['dif'] = macd.iloc[:, 0].astype('float32')
            df['macd'] = macd.iloc[:, 1].astype('float32')
            df['dea'] = macd.iloc[:, 2].astype('float32')
    except: pass

    # 4. KDJ
    try:
        kdj = df.ta.kdj(high='high', low='low', close='close', length=9, signal=3)
        if kdj is not None:
            df['k'] = kdj.iloc[:, 0].astype('float32')
            df['d'] = kdj.iloc[:, 1].astype('float32')
            df['j'] = kdj.iloc[:, 2].astype('float32')
    except: pass

    # 5. RSI
    try:
        df['rsi6'] = df.ta.rsi(close='close', length=6).astype('float32')
        df['rsi12'] = df.ta.rsi(close='close', length=12).astype('float32')
        df['rsi24'] = df.ta.rsi(close='close', length=24).astype('float32')
    except: pass

    # 6. BOLL
    try:
        boll = df.ta.bbands(close='close', length=20, std=2)
        if boll is not None:
            df['boll_lb'] = boll.iloc[:, 0].astype('float32')
            df['boll_up'] = boll.iloc[:, 2].astype('float32')
    except: pass

    # 7. å…¶ä»–
    try:
        df['cci'] = df.ta.cci(high='high', low='low', close='close', length=14).astype('float32')
        df['atr'] = df.ta.atr(high='high', low='low', close='close', length=14).astype('float32')
    except: pass

    return df

def process_resample(df_daily, freq, filename):
    """ç”Ÿæˆå‘¨çº¿/æœˆçº¿æ•°æ®"""
    print(f"   -> æ­£åœ¨ç”Ÿæˆ {freq} å‘¨æœŸæ•°æ® ({filename})...")
    
    # ä»…ä¿ç•™å¿…è¦åˆ—è¿›è¡Œ Resampleï¼Œå‡å°‘å†…å­˜å‹åŠ›
    # èµ„é‡‘æµç´¯åŠ ï¼Œä»·æ ¼å–é¦–å°¾
    agg_rules = {
        'open': 'first', 'close': 'last', 'high': 'max', 'low': 'min',
        'volume': 'sum', 'amount': 'sum', 'turn': 'mean',
        'peTTM': 'last', 'pbMRQ': 'last', 'mkt_cap': 'last', 'adjustFactor': 'last'
    }
    for c in ['net_flow_amount', 'main_net_flow', 'super_large_net_flow', 'large_net_flow', 'medium_small_net_flow']:
        if c in df_daily.columns: agg_rules[c] = 'sum'

    # æ‰§è¡Œ Resample
    df_res = df_daily.set_index('date').groupby('code').resample(freq).agg(agg_rules)
    df_res = df_res.dropna(subset=['close']).reset_index()
    df_res.sort_values(['code', 'date'], inplace=True)
    
    # è®¡ç®—åŸºç¡€å‡çº¿
    grouped = df_res.groupby('code')['close']
    for w in [5, 10, 20]:
        df_res[f'ma{w}'] = grouped.rolling(w).mean().reset_index(0, drop=True).astype('float32')
    
    # æ ¼å¼åŒ–
    df_res['date'] = df_res['date'].dt.strftime('%Y-%m-%d')
    df_res = optimize_float(df_res) # å†æ¬¡å‹ç¼©

    out_path = f"{OUTPUT_ENGINE}/{filename}"
    df_res.to_parquet(out_path, index=False, compression='zstd')
    print(f"      âœ… å·²ä¿å­˜: {len(df_res)} è¡Œ")
    
    # æ¸…ç†å†…å­˜
    del df_res
    gc.collect()

def main():
    print("ğŸš€ å¼€å§‹å…¨é‡åˆå¹¶ä¸å‘¨æœŸç”Ÿæˆ (å†…å­˜ä¼˜åŒ–ç‰ˆ)...")
    current_year = datetime.datetime.now().year
    
    # 1. åŠ è½½å†å²æ•°æ® (é€æ­¥åŠ è½½å¹¶å‹ç¼©)
    history_files = glob.glob(f"{CACHE_DIR}/*.parquet")
    df_history = pd.DataFrame()
    
    if history_files:
        print(f"ğŸ“¦ å‘ç°å†å²æ–‡ä»¶: {len(history_files)} ä¸ªï¼Œå¼€å§‹é€ä¸ªåŠ è½½...")
        dfs = []
        for f in history_files:
            # è¯»å–æ—¶ç«‹åˆ»è½¬ float32
            _df = pd.read_parquet(f)
            _df = optimize_float(_df)
            dfs.append(_df)
        
        df_history = pd.concat(dfs, ignore_index=True)
        # é‡Šæ”¾ä¸´æ—¶åˆ—è¡¨
        del dfs
        gc.collect() 
        print(f"âœ… å†å²æ•°æ®åŠ è½½å®Œæ¯•: {len(df_history)} è¡Œ")
    
    # 2. åŠ è½½ä»Šæ—¥å¢é‡
    k_files = glob.glob(f"{KLINE_DIR}/**/*.parquet", recursive=True)
    f_files = glob.glob(f"{FLOW_DIR}/**/*.parquet", recursive=True)
    f_map = {os.path.basename(f): f for f in f_files}
    
    print(f"ğŸ”¥ å¤„ç†ä»Šæ—¥å¢é‡: {len(k_files)} ä¸ª")
    dfs_new = []
    
    # åˆ†æ‰¹å¤„ç†å¢é‡ï¼Œé˜²æ­¢ list è¿‡å¤§
    for k_f in tqdm(k_files, desc="Reading New"):
        try:
            df_k = pd.read_parquet(k_f)
            if df_k.empty: continue
            
            df_k['date'] = pd.to_datetime(df_k['date'])
            
            fname = os.path.basename(k_f)
            if fname in f_map:
                df_f = pd.read_parquet(f_map[fname])
                if not df_f.empty:
                    df_f['date'] = pd.to_datetime(df_f['date'])
                    df_k = pd.merge(df_k, df_f, on=['date', 'code'], how='left')
            
            # ç«‹åˆ»ä¼˜åŒ–å†…å­˜
            df_k = optimize_float(df_k)
            dfs_new.append(df_k)
        except: pass
    
    if dfs_new:
        df_new = pd.concat(dfs_new, ignore_index=True)
        del dfs_new
        gc.collect()
    else:
        df_new = pd.DataFrame()

    # 3. å…¨é‡åˆå¹¶
    if df_history.empty and df_new.empty:
        print("âŒ æ— æ•°æ®å¤„ç†")
        return

    # ç»Ÿä¸€æ—¥æœŸæ ¼å¼
    if not df_history.empty: df_history['date'] = pd.to_datetime(df_history['date'])
    # df_new å·²ç»æ˜¯ datetime

    print("ğŸ”„ æ‰§è¡Œå…¨é‡åˆå¹¶...")
    df_total = pd.concat([df_history, df_new], ignore_index=True)
    
    # é‡Šæ”¾æ—§å˜é‡
    del df_history
    del df_new
    gc.collect()
    
    # å»é‡æ’åº
    print("ğŸ”„ æ’åºä¸å»é‡...")
    df_total.drop_duplicates(subset=['code', 'date'], keep='last', inplace=True)
    df_total.sort_values(['code', 'date'], inplace=True)
    
    # 4. è®¡ç®—å…¨é‡æŒ‡æ ‡ (è¿™æ˜¯æœ€åƒå†…å­˜çš„ä¸€æ­¥)
    print("ğŸ§® è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
    # ä½¿ç”¨ groupby apply ä¼šäº§ç”Ÿå¤§é‡ä¸´æ—¶ DataFrameï¼Œè¿™é‡Œè¦å°å¿ƒ
    # å¦‚æœä¾ç„¶ OOMï¼Œå¯ä»¥è€ƒè™‘åªè®¡ç®—ä»Šå¹´çš„æŒ‡æ ‡ï¼Œæˆ–è€…åˆ†æ‰¹è®¡ç®—
    df_total = df_total.groupby('code', group_keys=False).apply(calculate_indicators)
    
    # å†æ¬¡ä¼˜åŒ–ç±»å‹ (æŒ‡æ ‡è®¡ç®—å¯èƒ½å¼•å…¥ float64)
    df_total = optimize_float(df_total)
    gc.collect()

    # 5. ç”Ÿæˆå¤šå‘¨æœŸ
    print("ğŸ“… ç”Ÿæˆå¤šå‘¨æœŸæ•°æ®...")
    # è¿™é‡Œçš„ df_total å¾ˆå¤§ï¼Œä¼ å‚è¦æ³¨æ„
    process_resample(df_total, 'W-FRI', 'stock_weekly.parquet')
    process_resample(df_total, 'ME', 'stock_monthly.parquet')

    # 6. ä¿å­˜é€»è¾‘
    print("ğŸ’¾ å‡†å¤‡ä¿å­˜...")
    df_total['date'] = df_total['date'].dt.strftime('%Y-%m-%d')

    # A. æ›´æ–° Cache (ä»…ä¿ç•™å½“å¹´)
    # ä¸ºäº†é˜²æ­¢ Cache è¶Šæ¥è¶Šå¤§å¯¼è‡´ OOMï¼Œè¿™é‡Œä¸¥æ ¼åªç•™ä»Šå¹´
    df_hot = df_total[df_total['date'] >= f"{current_year}-01-01"].copy()
    cache_path = f"{CACHE_DIR}/stock_current_year.parquet"
    print(f"ğŸ“¦ ä¿å­˜ Cache: {cache_path} ({len(df_hot)} è¡Œ)")
    df_hot.to_parquet(cache_path, index=False, compression='zstd')
    
    # B. ä¿å­˜ OSS (ä¹Ÿæ˜¯åªä¼ ä»Šå¹´)
    oss_path = f"{OUTPUT_DAILY}/stock_{current_year}.parquet"
    print(f"â˜ï¸ ä¿å­˜ OSS: {oss_path}")
    df_hot.to_parquet(oss_path, index=False, compression='zstd')

    # C. (å¯é€‰) å¦‚æœä½ éœ€è¦åœ¨ Web ç«¯å›æµ‹å†å²ï¼Œå¯èƒ½éœ€è¦æŠŠå…¨é‡æ•°æ®å­˜ä¸€ä»½
    # ä½†è€ƒè™‘åˆ° 7GB å†…å­˜é™åˆ¶ï¼Œç”Ÿæˆ stock_full.parquet å¯èƒ½ä¼šå¤±è´¥
    # é‰´äºä½ çš„æ¶æ„æ˜¯ "æŒ‰å¹´å½’æ¡£"ï¼Œè¿™é‡Œæˆ‘ä»¬ä¸å†ç”Ÿæˆ stock_full.parquet
    # è€Œæ˜¯ä¾èµ– Release çš„å†å²æ–‡ä»¶ + OSS çš„ä»Šå¹´æ–‡ä»¶
    
    print("âœ… å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()
