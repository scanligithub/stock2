name: A-Share Daily ETL Pipeline

on:
  schedule:
    # 北京时间 21:00 (UTC 13:00) 运行
    - cron: '0 13 * * *'
  workflow_dispatch:

jobs:
  # === Job 1: 准备任务分片 ===
  prepare:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - run: pip install pandas baostock requests pyarrow
      
      - name: Generate Tasks
        run: python scripts/prepare_tasks.py
        
      - uses: actions/upload-artifact@v4
        with:
          name: task-slices
          path: task_slices/
          
      - uses: actions/upload-artifact@v4
        with:
          name: meta-data
          path: meta_data/

  # === Job 2: 并行下载 K线 (矩阵 0-19) ===
  download-kline:
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      matrix:
        task_index: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]
      max-parallel: 20
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: task-slices
          path: task_slices/
      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - run: pip install -r requirements.txt
      
      - name: Download KLine
        env:
          TASK_INDEX: ${{ matrix.task_index }}
        run: python scripts/download_kline.py
        
      - uses: actions/upload-artifact@v4
        with:
          name: kline_part_${{ matrix.task_index }}
          path: temp_kline/

  # === Job 3: 并行下载 资金流 (矩阵 0-19) ===
  download-fundflow:
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      matrix:
        task_index: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]
      max-parallel: 20
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: task-slices
          path: task_slices/
      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - run: pip install -r requirements.txt
      
      - name: Download FundFlow
        env:
          TASK_INDEX: ${{ matrix.task_index }}
        run: python scripts/download_fundflow.py
        
      - uses: actions/upload-artifact@v4
        with:
          name: flow_part_${{ matrix.task_index }}
          path: temp_fundflow/

  # === Job 4: 下载板块数据 ===
  process-sector:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - run: pip install -r requirements.txt
      - name: Download Sector Data
        run: python scripts/download_sector.py
      - uses: actions/upload-artifact@v4
        with:
          name: sector_data
          path: final_output/engine/

  # === Job 5: 合并 & 上传 ===
  finalize:
    needs: [download-kline, download-fundflow, process-sector, prepare]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      # 1. 下载所有中间文件
      - uses: actions/download-artifact@v4
        with:
          path: all_artifacts
          
      - name: Organize Artifacts
        run: |
          mkdir -p downloaded_kline downloaded_fundflow final_output/engine final_output/meta
          
          # 移动分片文件
          find all_artifacts -name "kline_part_*" -exec cp -r {}/. downloaded_kline/ \;
          find all_artifacts -name "flow_part_*" -exec cp -r {}/. downloaded_fundflow/ \;
          
          # 移动板块和元数据
          cp -r all_artifacts/sector_data/* final_output/engine/ 2>/dev/null || true
          cp all_artifacts/meta-data/stock_list.json final_output/meta/

      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - run: pip install -r requirements.txt
      
      # 2. 执行宽表合并
      - name: Merge Wide Table
        run: python scripts/merge_data.py

      # 3. 上传到 OSS
      - name: Setup ossutil
        uses: manyuanrong/setup-ossutil@v2.0
        with:
          endpoint: ${{ secrets.OSS_ENDPOINT }}
          access-key-id: ${{ secrets.OSS_ACCESS_KEY_ID }}
          access-key-secret: ${{ secrets.OSS_ACCESS_KEY_SECRET }}

      - name: Upload to OSS
        run: |
          # 1. 上传元数据 (stock_list.json)
          ossutil cp -f final_output/meta/stock_list.json oss://${{ secrets.OSS_BUCKET }}/meta/stock_list.json
          
          # 2. 上传个股宽表 (支持并发)
          ossutil cp -f final_output/engine/stock_full.parquet oss://${{ secrets.OSS_BUCKET }}/engine/stock_full.parquet --jobs=10 --part-size=10240000
          
          # 3. 上传板块宽表
          ossutil cp -f final_output/engine/sector_full.parquet oss://${{ secrets.OSS_BUCKET }}/engine/sector_full.parquet
          ossutil cp -f final_output/engine/sector_list.parquet oss://${{ secrets.OSS_BUCKET }}/engine/sector_list.parquet || true

          echo "✅ 上传完成！"
